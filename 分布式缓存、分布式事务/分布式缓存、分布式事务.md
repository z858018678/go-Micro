# 分布式缓存、分布式事务

一个好的架构系统，第一跟他的缓存还有消息队列的设计，第二点是存储，第三就是微服务治理相关的，配置中心等等


缓存、存储、队列 中间件

sync.pool对象池的实现


## 缓存

### 缓存选型

- memcache

	- 功能：提供简单的kv cache储存，value的大小不超过1mb
	- 特点

		- 在缓存大文件的时候速度比较快
		- 多线程
		- 内存管理使用的是slab（块），存在一定的浪费，如果大量接近item,建议增加
		- 内存池设计

- redis

	- 特点

		- redis.io，指令有源码
		- 有丰富的数据类型，支持增量修改

	- 核心作用

		- 数据索引

	- 疑问

		- 内存碎片
		- 为什么要做内存对齐

- proxy

	- 协议翻译，普通的redis协议对接集群redis
	- 缓存代理

- redis和memcache的相差

	- 
	- 随着redis的不断优化，memcache会逐渐淘汰
	- redis 6.0版本后io线程之后，写入能力提升，写大文件的能力提升

- 一致性hash缓存

	- 
	- 有限负载，一致性hash

- redis-cluser集群, slot槽点

	- 
	- 先找槽，再找节点

### 缓存模式

- db和cache数据一致性

	- 
	- 1、操作db
2、操作cache
3、job回放dbLog,做缓存补偿

		- 还是会出现缓存不一致，异步无法保证顺序的有序性，所以会导致缓存覆盖

			- 

		- 弥补方法，读的时候，如果发生key miss,要写如这个方法时，需要判断他是否存在然后再从数据库读，数据库里有数据在更新缓存的时候，在判断一次，这个数据是否存在，如果存在则不更新

			- 

		- 用setEx改为setNx

- 多级缓存

	- 

		- 概述

			- 
			- 在一个bff服务调用多个原子服务进行查询时，这样查询的效率和负担会过大，这个时候就需要加入二级缓存来进行缓存，每个原子服务生个一个缓存，查不到的缓存就再调用服务

	- 保证多级缓存的一致性

		- 清理缓存的优先级，先清理下游的缓存再清理上级的缓存
		- 下游缓存超时时间要大于上游，防止穿透回源

- 热点缓存

	- 小表广播利用本地缓存广播
	- 将远程缓存升级为本地缓存
	- 主动预热，监控预热
	- 多集群缓存，多副本

- 穿透缓存

	- singlefly

		- 对关键字进行一致性 hash，使其某一个维度的 key 一定命中某个节点，然后在节点内使用互斥锁，保证归并回源，但是对于批量查询无解

	- 分布式锁

		- 设置一个 lock key，有且只有一个人成功，并且返回，交由这个人来执行回源操作，其他候选者轮训 cache 这个 lock key，如果不存在去读数据缓存，hit 就返回，miss 继续抢锁

	- 队列

		- 如果 cache miss，交由队列聚合一个key，来 load 数据回写缓存，对于 miss 当前请求可以使用 singlefly 保证回源，如评论架构实现。适合回源加载数据重的任务，比如评论 miss 只返回第一页，但是需要构建完成评论数据索引

	- lease

		- 通过加入 lease 机制，可以很好避免这两个问题，lease 是 64-bit 的 token，与客户端请求的 key 绑定，对于过时设置，在写入时验证 lease，可以解决这个问题；对于 thundering herd，每个key 10s 分配一次，当 client 在没有获取到 lease 时，可以稍微等一下再访问 cache，这时往往cache 中已有数据。（基础库支持 & 修改 cache 源码）

### 缓存技巧

- Incast Congestion（可以理解为，network 有很多switch，router 啥的，一旦一次性发一堆包，这些包同时到达 switch，这些 switch 就会忙不过来）

	- 使用“Window size”，类似tcp的滑动窗口

- 易读性的前提下，key 设置尽可能小，减少资源的占用，redis value 可以用 int 就不要用string，对于小于 N 的 value，redis 内部有 shared_object 缓存。

- 拆分 key。主要是用在 redis 使用 hashes 情况下。同一个 hashes key 会落到同一个 redis 节点，hashes 过大的情况下会导致内存及请求分布的不均匀。考虑对 hash 进行拆分为小的hash，使得节点内存均匀及避免单节点请求热点。

- 空缓存设置。对于部分数据，可能数据库始终为空，这时应该设置空缓存，避免每次请求都缓存 miss 直接打到 DB。


	- 减少回源，类似nginx，空缓存也会赋值

- 空保护策略
- 读失败之后写的策略

	- 读失败有两种情况，1、没有缓存2、网络原因。遇到这种就直接不写

- 序列化使用 protobuf，尽可能减少 size

	- cpu换空间

- memcache 缓存技巧

	- 标识 compress、encoding、large value 等
	- memcache 支持 gets，尽量读取，尽可能的 pipeline，减少网络往返；

	- 使用二进制协议，支持 pipeline delete，UDP 读取、TCP 更新

		- 批量删除，批量操作

- redis缓存技巧

	- 增量更新一致性：EXPIRE、ZADD/HSET 等，保证索引结构体务必存在的情况下去操作新增数据

		- 过滤掉不符合条件的缓存

	- BITSET: 存储每日登陆用户，单个标记位置（boolean），为了避免单个 BITSET 过大或者热点，需要使用 region sharding，比如按照mid求余 %和/ 10000，商为 KEY、余数作为offset
	- List:抽奖的奖池、顶弹幕，用于类似 Stack PUSH/POP操作
	- Sortedset: 翻页、排序、有序的集合，杜绝 zrange 或者 zrevrange 返回的集合过大；

	- Hashs: 过小的时候会使用压缩列表、过大的情况容易导致 rehash 内存浪费，也杜绝返回hgetall，对于小结构体，建议直接使用 memcache KV；

	- String: SET 的 EX/NX 等 KV 扩展指令，SETNX 可以用于分布式锁、SETEX 聚合了SET + EXPIRE；

	- Sets: 类似 Hashs，无 Value，去重等；

	- 尽可能的 PIPELINE 指令，但是避免集合过大；

	- 避免超大 Value；


## 分布式事务

### 数据最终一致性

### 事务消息

- 事务消息的架构图

	- 分两个服务，一个服务加钱之后将消息凭证发送出来，另外一个服务去拿消息凭证来加钱

- 如何保持消息的最终一致性，本地mysql和masg一致的问题

	- 事务消息一旦被可靠的持久化，我们整个分布式事务，变为了最终一致性，消息的消费才能保障最终业务数据的完整性，所以我们要尽最大努力，把消息送达到下游的业务消费方，称为：Best Effort。只有消息被消费，整个交易才能算是完整完结。


		- Best Effort（尽最大努力交付）

			- 支付成功之后，可以不断的去消费事务消息
			- 架构

	- Transactional outbox

		- Transactional outbox，支付宝在完成扣款的同时，同时记录消息数据，这个消息数据与业务数据保存在同一数据库实例里（消息记录表表名为 msg）
		- 区别就是通过一张表来记录消息消费成功

	- Polling publisher

		- Polling publisher，我们定时的轮询msg 表，把 status = 1 的消息统统拿出来消费，可以按照自增 id 排序，保证顺序消费。在这里我们独立了一个  pay_task 服务，把拖出来的消息 publish 给我们消息队列，balance 服务自己来消费队列，或者直接 rpc 发送给 balance 服务，处理成功后在直接同志改状态

			- 

	- Transaction log tailing

		- 使用 canal 订阅msg表以后，是实时流式消费数据，在消费者 balance 或者 balance-job 必须努力送达到。所有努力送达的模型，必须是先预扣（预占资源）的做法。


			- 

	- 幂等

		- 全局唯一 ID+ 去重表

			- 余额宝这边增加消息应用状态表 msg_apply，通俗来说就是个账本，用于记录消息的消费情况，每次来一个消息，在真正执行之前，先去消息应用状态表中查询一遍，如果找到说明是重复消息，丢弃即可，如果没找到才执行，同时插入到消息应用状态表（同一事务）。

			- 可以跳过已经跳过的事务处理

### 2PC,两阶段提交

- 架构
- 构成

	- 一个事务协调者（coordinator）：负责协调多个参与者进行事务投票及提交(回滚)
	- 多个事务参与者（participants）：即本地事务执行者

- 步骤

	- 1、投票阶段（voting phase）：协调者将通知事务参与者准备提交或取消事务，然后进入表决过程。参与者将告知协调者自己的决策：同意（事务参与者本地事务执行成功，但未提交）或取消（本地事务执行故障）；
	- 2、提交阶段（commit phase）：收到参与者的通知后，协调者再向参与者发出通知，根据反馈情况决定各参与者是否要提交还是回

### 2PC Message Queue

- 分布式事务

### tcc

- 操作步骤

	- Try 操作做业务检查及资源预留，Conﬁrm 做业务确认操作，Cancel 实现一个与 Try 相反的操作即回滚操作。
TM 首先发起所有的分支事务的 Try 操作，任何一个分支事务的 Try 操作执行失败，TM 将会发起所有分支事务的 Cancel 操作，若 Try 操作全部成功，TM 将会发起所有分支事务的 Conﬁrm 操作，其中 Conﬁrm/Cancel 操作若执行失败，TM 会进行重试。


- 

