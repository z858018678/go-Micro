# 《评论设计系统设计点》

## comment-service，专注在评论数据处理(认真想下 Separation of Concerns)

### 读的逻辑设计

- Cache-Aside 模式，先读取缓存，再读取存储。
早期 cache rebuild 是做到服务里的，对于重建逻辑，一般会使用 read ahead 的思路，即预读，用户访问了第一页，很有可能访问第二页，所以缓存会超前加载，避免频繁 cache miss。当缓存抖动是否，特别容易引起集群 hundering herd 现象，大量的请求会触发 cache rebuild，因为使用了预加载，容易导致服务 OOM。所以我们开到回源的逻辑里，我们使用了消息队列来进行逻辑异步化，对于当前请求只返回 mysql 中部分数据即止。


### 写的逻辑设计

- 使用Kafka
使用kafka分区每个主题对应的是一个分区，让同一个主题在同一个分区队列之中，达到全局并行局部串行的一个生产消费方式。

可以按照 hash(comment_subject) % N(partitions) 的方式进行分发，方便每个主题串行消费

### 设计经验总结

- 我们一开始是 comment-service 和 comment 是一层，业务耦合和功能耦合在一起，1、非常不利于迭代，2、是架构层次来说，迭代隔离也是好的。

## comment

### comment 作为 BFF，是面向端，面向平台，面向业务组合的服务。所以平台扩展的能力，我们都在 comment 服务来实现，方便统一和准入平台，以统一的接口形式提供平台化的能力。


## 数据库设计

### 读写隔离

- 构建详细信息表，以及统计表

### 索引隔离

- 索引、内容分离，方便 mysql datapage 缓存更多的 row，如果和 context 耦合，会导致更大的 IO。长远来看 content 信息可以直接使用 KV storage 存储。
- 表都有主键，即 cluster index，是物理组织形式存放的，comment_content 没有 id，是为了减少一次 二级索引查找，直接基于主键检索，同时 comment_id 在写入要尽可能的顺序自增

## 缓存设计

### comment_subject_cache: 对应主题的缓存，value 使用 protobuf 序列化的方式存入。我们早期使用 memcache 来进行缓存，因为 redis 早期单线程模型，吞吐能力不高

### comment_index_cache: 使用 redis sortedset 进行索引的缓存，索引即数据的组织顺序，而非数据内容。参考过百度的贴吧，他们使用自己研发的拉链存储来组织索引，我认为 mysql 作为主力存储，利用 redis 来做加速完全足够，因为 cache miss 的构建，我们前面讲过使用 kafka 的消费者中处理，预加载少量数据，通过增量加载的方式逐渐预热填充缓存，而 redis sortedset skiplist 的实现，可以做到 O(logN) + O(M) 的时间复杂度，效率很高。


## 热点评论导致的缓存击穿的问题解决

### 1、归并回源，让一个进程批量的读数据库数据

## 热点设计

### 1、自动识别热点的方式进行区分对待，热点过高的时候远程缓存升级为本地缓存

### 2、滑动窗口统计，在内存中使用 hashmap 统计每个 key 的访问频次，这里可以使用滑动窗口统计，即每个窗口中，维护一个 hashmap，之后统计所有未过去的 bucket，汇总所有 key 的数据。


