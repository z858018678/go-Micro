# 微服务可用性设计

## 隔离

### 概念

- 对系统或者资源进行分割

### 意义、作用

- 当系统发生故障时能限定传播范围和影响范围，发生故障后只有出问题的服务不可用，其他的服务就可以用

### 隔离的方式

- 轻重隔离

	- 核心、快慢、热点
	- 核心隔离

		- 将服务分级区分隔离，隔离级别的越高的安全性能就越高，多集群来提升核心集群
		- sla的要求不一样

	- 快慢隔离

		- 讲

	- 热点数据

		- 滑动窗口统计，区分热点数据，本地缓存，小表广播，就是把每个进程atomic.value
		- 主动预热，提前将远程缓存，升级为本地缓存
		- mapjion

- 服务层隔离

	- 读写分离（cqrs）

		- 主从分离
		- 不适合对数据一致性要求太高的程序

	- 动静分离

		- 数据库表的设计，读写分离，
不怎么更新的字段和经常更新的字段拆开
		- 图片，cdn缓存加速，将静态资源和动态api资源相隔离

- 物理隔离

	- 进程、线程、集群、机房
	- 进场隔离

		- k8s docker容器编排

			- cGropLinux内核隔离网络、cup

	- 线程隔离

		- go是非阻塞io Nonbloking,不会去阻塞线程

## 超时控制

### 网络超时原因

- 网络部具有不确定性
- 服务端和客户端的超时策略不一样
- “默认策略”

### 控制

- 使用garpcTimeOut头字段设置一个超时时间，一直传到下游，全局超时控制
- 使用公共配置模版，公共配置中心，设置超时时间，都遵守这个时间
- 进程间的超时控制，context.withTime

## 过载保护

### 单机版的限流方法，保护系统不被拖垮。超过这个指标就减少流量

- 令牌桶:漏桶算法思路很简单，水（请求）先进入到漏桶里，漏桶以一定的速度出水，当水流入速度过大会直接溢出，可以看出漏桶算法能强行限制数据的传输速率。
- 漏桶算法:令牌桶算法的原理是系统会以一个恒定的速度往桶里放入令牌，而如果请求需要被处理，则需要先从桶里获取一个令牌，当桶里没有令牌可取时，则拒绝服务。
- 缺点，设置的阈值太被动，不能快速适应流量变化

### 自适应的限流算法就是过载保护，根据系统的负载情况自动来丢弃流量

- 利特儿法则

	- 利用cpu、内存、信号量来控制
	- codel算法和bbr来控制流量

- 服务器零近过载的时候，qps*延迟，来算出来一个最大吞吐量，到达这个最大值就限流，抛弃一定的负载。自保

## 限流

### 在一段时间内限制多少个技术请求

### 限流的目的，可以为了保护系统

### 分布式限流

### 按类型限流，限流的方式不同

### 熔断

- 断路器(Circuit Breakers): 为了限制操作的持续时间，我们可以使用超时，超时可以防止挂起操作并保证系统可以响应。防止重复操作

### 客户端限流

- 限制请求频率

### gutter

- 双熔断

## 降级

### 作用

- 通过降级回复来减少工作量，或者丢弃不重要的请求。我们通常提供降低回复的质量来答复减少所需的计算量或者时间。

### 自动降级的条件

- 确定具体采用哪个指标作为流量评估和优雅降级的决定性指标(如，CPU、延迟、队列长度、线程数量、错误等)。


### 降级实现需要考虑的点

- 优雅降级不应该被经常触发 - 通常触发条件现实了容量规划的失误，或者是意外的负载
- 演练，代码平时不会触发和使用，需要定期针对一小部分的流量进行演练，保证模式的正常。

- 应该足够简单。


### 本质

- 提供有损的服务

### 降级的策略

- UI 模块化，非核心模块降级。
- BFF 层聚合 API，模块降级。
- 页面上一次缓存副本。
- 默认值、热门推荐等。
- 流量拦截 + 定期数据缓存(过期副本策略)。
- 页面降级、延迟服务、写/读降级、缓存降级
- 抛异常、返回约定协议、Mock 数据、Fallback 处理

## 重试

### 当请求返回错误(例: 配额不足、超时、内部错误等)，对于 backend 部分节点过载的情况下，倾向于立刻重试，但是需要留意重试带来的流量放大

### 重试的策略

- 限制重试次数和基于重试分布的策略(重试比率: 10%)。
- 随机化、指数型递增的重试周期: exponential ackoff + jitter。
- client 测记录重试次数直方图，传递到 server，进行分布判定，交由 server 判定拒绝。
- 只应该在失败的这层进行重试，当重试仍然失败，全局约定错误码“过载，无须重试”，避免级联重试。

## 负载均衡

### 数据中心内部的负载均衡


### 作用

- 在理想情况下，某个服务的负载会完全均匀地分发给所有的后端任务。在任何时刻，最忙和最不忙的节点永远消耗同样数量的CPU。


### 目标

- 均衡的流量分发。
- 可靠的识别异常节点。
- scale-out，增加同质节点扩容。
- 减少错误，提高可用性。

## 最佳实践

### 变更管理:
70％的问题是由变更引起的，恢复可用代码并不总是坏事。
避免过载:
过载保护、流量调度等。
依赖管理:
任何依赖都可能故障，做 chaos monkey testing，注入故障测试。
优雅降级:
有损服务，避免核心链路依赖故障。
重试退避:
退让算法，冻结时间，API retry detail 控制策略。
超时控制:
进程内 + 服务间 超时控制。
极限压测 + 故障演练。
扩容 + 重启 + 消除有害流量。


